{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e96af091-39ec-49c9-a6e3-109a7d1a31ed",
   "metadata": {},
   "source": [
    "# Water Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74684033-b6c4-4345-9e89-33947c5984bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools import mask as maskUtils\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from segmentation_models_pytorch import Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04673239-488c-4d48-8826-5ecf8de99f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the model\n",
    "unet_model_water = Unet(\n",
    "    encoder_name=\"efficientnet-b3\",  # Choose your backbone (e.g., \"resnet34\", \"efficientnet-b3\", etc.)\n",
    "    encoder_weights=\"imagenet\",  # Use pre-trained weights\n",
    "    in_channels=3,  # Input channels (e.g., 3 for RGB images)\n",
    "    classes=1  # Number of output classes\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8477acfd-737a-41d6-9149-c0397f43433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((640, 640)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "input_tensor = torch.randn(1, 3, 640, 640)  # Batch size of 1, 3 channels (RGB), 640x640 image\n",
    "output = unet_model_water(input_tensor)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817a8c2b-0fc4-458f-ac33-1ad8af2eaff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, images_dir, masks_dir, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.masks_dir = masks_dir\n",
    "        self.transform = transform\n",
    "        self.image_filenames = os.listdir(images_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.images_dir, self.image_filenames[idx])\n",
    "        mask_path = os.path.join(self.masks_dir, self.image_filenames[idx].replace('.jpg', '')+'_mask.png')  # Adjust file extension if needed\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Debugging prints\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Image not found or unable to load: {image_path}\")\n",
    "        if mask is None:\n",
    "            raise ValueError(f\"Mask not found or unable to load: {mask_path}\")\n",
    "\n",
    "        # Ensure proper dimensions\n",
    "        if len(image.shape) != 3 or image.shape[2] != 3:\n",
    "            raise ValueError(f\"Unexpected image shape: {image.shape}\")\n",
    "\n",
    "        # Resize or pad image and mask to be divisible by 32\n",
    "        # image = self.resize_or_pad(image)\n",
    "        # mask = self.resize_or_pad(mask)\n",
    "\n",
    "        # Normalize image\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # mask = mask // 51  # Adjust if necessary\n",
    "        mask = np.where(mask == 4, 1, 0).astype('float32')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return torch.tensor(image, dtype=torch.float32).permute(0, 1, 2), torch.tensor(mask, dtype=torch.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d46291-1d77-4f28-83fa-c483ff7d505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_dir = 'wildfire-week8/test/original'\n",
    "test_masks_dir = 'wildfire-week8/test/mask'\n",
    "# Create datasets\n",
    "test_dataset_water = SegmentationDataset(test_images_dir, test_masks_dir, transform)\n",
    "\n",
    "# Create data loaders\n",
    "test_loader_water = DataLoader(test_dataset_water, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570e8405-deaa-460e-9e68-7a4c9c470a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_predictions_with_overlays(model, model_state_path, test_loader, output_folder):\n",
    "    \"\"\"\n",
    "    Displays images with overlayed ground truth and predicted masks, saving only the predicted overlay images.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained PyTorch model used for predictions.\n",
    "    - model_state_path: Path to the .pth file containing the model's state dictionary.\n",
    "    - test_loader: DataLoader providing test images and masks.\n",
    "    - output_folder: Folder where overlayed images will be saved.\n",
    "    \"\"\"\n",
    "    # Load model weights from the .pth file\n",
    "    model.load_state_dict(torch.load(model_state_path))\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    os.makedirs(output_folder, exist_ok=True)  # Ensure output folder exists\n",
    "    \n",
    "    water_images = []\n",
    "    water_masks = []\n",
    "    \n",
    "    # Collect images with water (mask has value 1)\n",
    "    for images, masks in test_loader:\n",
    "        for i in range(images.size(0)):  # Iterate over batch\n",
    "            water_images.append(images[i].unsqueeze(0))\n",
    "            water_masks.append(masks[i].unsqueeze(0))\n",
    "    \n",
    "    if len(water_images) == 0:\n",
    "        print(\"No water images found in the test set.\")\n",
    "        return\n",
    "    \n",
    "    # Convert lists to tensors\n",
    "    water_images = torch.cat(water_images, dim=0)\n",
    "    water_masks = torch.cat(water_masks, dim=0)\n",
    "    \n",
    "    # Define the new mask color as RGB normalized values\n",
    "    new_color = np.array([15/255, 94/255, 156/255])  # Normalize RGB values for 0f5e9c\n",
    "    alpha = 0.9  # Transparency factor\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx in range(len(water_images)):\n",
    "            image = water_images[idx].to(torch.float32)  # Get the image\n",
    "            mask = water_masks[idx].squeeze(0)  # Get the corresponding mask\n",
    "            \n",
    "            output = model(image.unsqueeze(0))  # Get prediction from the model\n",
    "            prediction = (output > 0.5).float().squeeze(0)  # Binarize the output (threshold = 0.5)\n",
    "            \n",
    "            # Prepare image, mask, and prediction for overlay\n",
    "            img_np = image.squeeze().permute(1, 2, 0).cpu().numpy()  # (C, H, W) -> (H, W, C)\n",
    "            img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min())  # Normalize to [0, 1]\n",
    "            \n",
    "            mask_np = mask.cpu().numpy()  # Convert mask to numpy\n",
    "            pred_np = prediction.cpu().numpy().squeeze()  # Convert prediction to numpy and remove extra dimensions\n",
    "            \n",
    "            # Overlay mask onto original image (use custom color)\n",
    "            img_with_mask = img_np.copy()\n",
    "            img_with_mask[mask_np == 1] = new_color  # Apply custom color for ground truth mask\n",
    "            img_with_mask = (alpha * img_with_mask + (1 - alpha) * img_np)  # Blend with original image\n",
    "            \n",
    "            img_with_pred = img_np.copy()\n",
    "            img_with_pred[pred_np == 1] = new_color  # Apply the predicted mask with the custom color\n",
    "            img_with_pred = (alpha * img_with_pred + (1 - alpha) * img_np)  # Blend with original image\n",
    "\n",
    "            # Save only the predicted overlay image\n",
    "            img_filename = f\"predicted_overlay_{idx}.png\"\n",
    "            img_path = os.path.join(output_folder, img_filename)\n",
    "\n",
    "            # Plot all three images\n",
    "            fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "            \n",
    "            # Display original image\n",
    "            axs[0].imshow(img_np)\n",
    "            axs[0].set_title('Original Image')\n",
    "            axs[0].axis('off')\n",
    "            \n",
    "            # Display original image with ground truth mask\n",
    "            axs[1].imshow(img_with_mask)\n",
    "            axs[1].set_title('Original Image with Ground Truth Mask')\n",
    "            axs[1].axis('off')\n",
    "            \n",
    "            # Display original image with predicted mask\n",
    "            axs[2].imshow(img_with_pred)\n",
    "            axs[2].set_title('Original Image with Predicted Mask')\n",
    "            axs[2].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()  # Show the three images\n",
    "            \n",
    "            # Save the predicted overlay image only\n",
    "            plt.imsave(img_path, img_with_pred)  # Save the predicted overlay image\n",
    "            plt.close(fig)  # Close the figure to avoid display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80afc6b-51d2-4da2-adf8-39ac645a3a84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_path = \"best_unet_water_model_week8.pth\"\n",
    "output_folder = \"wildfire-week8/test/water-overlay\"\n",
    "# Call the function to visualize random images\n",
    "save_predictions_with_overlays(unet_model_water, model_path, test_loader_water, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e65a32-7b29-4277-af38-b9d3cfa3a734",
   "metadata": {},
   "source": [
    "# Alive Tree Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6844d351-2300-407a-97af-bac10f2a5fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def color_based_segmentation(image):\n",
    "    \"\"\"Generates a mask for alive trees based on color segmentation.\"\"\"\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    lower_green = np.array([25, 40, 20])   # Lowered brightness and saturation to capture darker greens\n",
    "    upper_green = np.array([100, 255, 180])\n",
    "    green_mask = cv2.inRange(hsv_image, lower_green, upper_green)\n",
    "\n",
    "    return green_mask\n",
    "\n",
    "def process_images(original_folder, water_mask_folder, water_mask_applied_folder, output_format='png'):\n",
    "    \"\"\"Processes all images in the specified folders,\n",
    "       applies tree detection methods, and visualizes results.\n",
    "       \n",
    "    Parameters:\n",
    "    - output_format: The format to save the output images ('png', 'jpg', 'tiff', etc.)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get all original images\n",
    "    original_images = [f for f in os.listdir(original_folder) if f.lower().endswith(('jpg', 'png', 'jpeg'))]\n",
    "    \n",
    "    # Loop through each original image file\n",
    "    for image_file in original_images:\n",
    "        # Read the original image\n",
    "        original_image_path = os.path.join(original_folder, image_file)\n",
    "        original_image = cv2.imread(original_image_path)\n",
    "        if original_image is None:\n",
    "            print(f\"Error: Could not read original image from {original_image_path}.\")\n",
    "            continue\n",
    "\n",
    "        # Read the corresponding water mask (e.g., predicted_mask_0.png)\n",
    "        water_mask_file = f'predicted_mask_{image_file.split(\".\")[0].split(\"_\")[-1]}.png'\n",
    "        water_mask_path = os.path.join(water_mask_folder, water_mask_file)\n",
    "        water_mask = cv2.imread(water_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if water_mask is None:\n",
    "            print(f\"Error: Could not read water mask from {water_mask_path}.\")\n",
    "            continue\n",
    "\n",
    "        # Read the water mask applied image (e.g., predicted_overlay_1.png)\n",
    "        water_mask_applied_file = f'predicted_overlay_{image_file.split(\".\")[0].split(\"_\")[-1]}.png'\n",
    "        water_mask_applied_path = os.path.join(water_mask_applied_folder, water_mask_applied_file)\n",
    "        water_mask_applied_image = cv2.imread(water_mask_applied_path)\n",
    "\n",
    "        if water_mask_applied_image is None:\n",
    "            print(f\"Error: Could not read water mask applied image from {water_mask_applied_path}.\")\n",
    "            continue\n",
    "\n",
    "        # Generate the mask for alive trees\n",
    "        alive_tree_mask = color_based_segmentation(original_image)\n",
    "\n",
    "        # Exclude areas identified as water in the water mask\n",
    "        alive_tree_mask[water_mask > 0] = 0  # Set alive tree mask to 0 where water mask is present\n",
    "\n",
    "        # Create transparent overlay for alive trees\n",
    "        alive_tree_overlay = np.zeros_like(original_image, dtype=np.uint8)\n",
    "        alive_tree_overlay[alive_tree_mask > 0] = [0, 255, 0]  # Green for alive trees\n",
    "\n",
    "        # Combine overlays with the provided water mask applied image\n",
    "        alpha_trees = 0.8  # Transparency for tree overlay\n",
    "        final_overlay_image = cv2.addWeighted(water_mask_applied_image, 1, alive_tree_overlay, alpha_trees, 0)\n",
    "\n",
    "        # Save the final overlay image\n",
    "        output_filename = f'final_overlay_{os.path.splitext(image_file)[0]}.{output_format}'\n",
    "        output_path = os.path.join(water_mask_applied_folder, output_filename)  # Save in the same folder\n",
    "        cv2.imwrite(output_path, final_overlay_image)\n",
    "\n",
    "        # Visualize the original image, water mask applied image, and final image with tree overlay\n",
    "        plt.figure(figsize=(15, 5))\n",
    "\n",
    "        # Show original image\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Original Image')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Show water mask applied image\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(cv2.cvtColor(water_mask_applied_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Image with Water Mask Applied')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Show final image with both overlays\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(cv2.cvtColor(final_overlay_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Final Image with Alive Tree Overlay')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    print(f\"Final overlay images saved in '{water_mask_applied_folder}' with format '{output_format}'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ad9f8c-0206-407d-a352-4b368b2d2bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "original_folder = 'wildfire-week8/test/testloader-original'        # Change this to your image folder path\n",
    "water_mask_folder = 'wildfire-week8/test/testloader-predict'\n",
    "water_mask_applied_folder = 'wildfire-week8/test/water-overlay'# Change this to your water mask folder path\n",
    "# output_folder = 'wildfire-week8/test/hsv'  \n",
    "process_images(original_folder, water_mask_folder, water_mask_applied_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4f6672-d02b-45fc-838f-5963a7f36037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def display_image_from_path(image_path):\n",
    "    \"\"\"\n",
    "    Display an image from a given file path.\n",
    "\n",
    "    Parameters:\n",
    "    image_path (str): The file path to the image.\n",
    "    \"\"\"\n",
    "    # Load the image from the path and convert to an RGB numpy array\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    rgb_array = np.array(image)\n",
    "    \n",
    "    original_image = cv2.imread(image_path)\n",
    "    hsv_image = cv2.cvtColor(original_image, cv2.COLOR_RGB2HSV)\n",
    "    hsv_array = np.array(hsv_image)\n",
    "    # print(rgb_array[0])\n",
    "    print(hsv_array[320, -100:])\n",
    "    # # Display the image\n",
    "    # plt.imshow(rgb_array)\n",
    "    # plt.axis('off')  # Hide axes for a cleaner look\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddf9ed5-b7d2-404e-a3c8-c099a2668c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def process_image(image_path):\n",
    "    \"\"\"\n",
    "    Processes a single image, applies an alive tree mask, and visualizes the original and masked images.\n",
    "\n",
    "    Parameters:\n",
    "    - image_path (str): Path to the original image.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the original image\n",
    "    original_image = cv2.imread(image_path)\n",
    "    if original_image is None:\n",
    "        print(f\"Error: Could not read image from {image_path}.\")\n",
    "        return\n",
    "\n",
    "    # Generate alive tree mask using a color-based segmentation function\n",
    "    alive_tree_mask = color_based_segmentation(original_image)\n",
    "\n",
    "    # Create an overlay for alive trees\n",
    "    alive_tree_overlay = np.zeros_like(original_image, dtype=np.uint8)\n",
    "    alive_tree_overlay[alive_tree_mask > 0] = [0, 255, 0]  # Green color for alive trees\n",
    "\n",
    "    # Combine the original image with the tree mask overlay\n",
    "    alpha_trees = 0.8\n",
    "    final_image_with_overlay = cv2.addWeighted(original_image, 1, alive_tree_overlay, alpha_trees, 0)\n",
    "\n",
    "    # Visualize the original and masked images\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Show original image\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Show image with alive tree overlay\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(cv2.cvtColor(final_image_with_overlay, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Image with Alive Tree Overlay')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1234723-5b56-4b93-9c52-6cdebcff41f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_image('wildfire-week8/test/Layer 0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3193a5-86bb-4acc-922c-19896cac98d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def increase_highlights_auto_threshold(image_path, output_path, highlight_amount=2, percentile=50):\n",
    "    \"\"\"\n",
    "    Increases highlights in the image by brightening the brightest regions.\n",
    "    Automatically determines a threshold based on the brightness distribution.\n",
    "    \n",
    "    Parameters:\n",
    "    - image_path: Path to the image file.\n",
    "    - highlight_amount: Multiplier for highlight brightness (e.g., 1.2 = 20% increase).\n",
    "    - percentile: Percentile to use for determining the brightness threshold.\n",
    "    \n",
    "    Returns:\n",
    "    - Processed image with increased highlights.\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB for display\n",
    "\n",
    "    # Convert to HSV (Hue, Saturation, Value) for better control over brightness\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "\n",
    "    # Calculate the percentile threshold based on brightness values\n",
    "    threshold = np.percentile(v, percentile)\n",
    "\n",
    "    # Increase brightness only for pixels above the threshold\n",
    "    highlight_mask = v > threshold\n",
    "    v[highlight_mask] = np.clip(v[highlight_mask] * highlight_amount, 0, 255)\n",
    "\n",
    "    # Merge channels back and convert to RGB\n",
    "    hsv_highlighted = cv2.merge([h, s, v])\n",
    "    highlighted_image = cv2.cvtColor(hsv_highlighted, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "    # Save the processed image\n",
    "    highlighted_image_bgr = cv2.cvtColor(highlighted_image, cv2.COLOR_RGB2BGR)  # Convert back to BGR for saving\n",
    "    cv2.imwrite(output_path, highlighted_image)\n",
    "\n",
    "    # Display images\n",
    "    # plt.figure(figsize=(12, 6))\n",
    "    # plt.subplot(1, 2, 1)\n",
    "    # plt.imshow(image)\n",
    "    # plt.title(\"Original Image\")\n",
    "    # plt.axis('off')\n",
    "\n",
    "    # plt.subplot(1, 2, 2)\n",
    "    # plt.imshow(highlighted_image)\n",
    "    # plt.title(\"Image with Increased Highlights\")\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "\n",
    "    return highlighted_image\n",
    "\n",
    "# Example usage\n",
    "increase_highlights_auto_threshold(\"wildfire-week8/test/testloader-original/original_image_21.png\",\"wildfire-week8/test/highlighted.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d616f0b-67dc-444f-ac38-569a539ff9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_image('wildfire-week8/test/highlighted.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04e424d-4dee-45cd-ae42-e68006f60841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def filter_and_visualize_high_contrast_images(folder_path, contrast_threshold):\n",
    "    \"\"\"\n",
    "    Filters and visualizes images with high contrast from a specified folder.\n",
    "    \n",
    "    Parameters:\n",
    "    - folder_path: Path to the folder containing images.\n",
    "    - contrast_threshold: Threshold for standard deviation to consider an image as high contrast.\n",
    "    \n",
    "    Returns:\n",
    "    - List of file paths of high-contrast images.\n",
    "    \"\"\"\n",
    "    high_contrast_images = []\n",
    "    \n",
    "    # Loop through each image in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Read the image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            continue  # Skip non-image files or corrupted images\n",
    "\n",
    "        # Convert to grayscale for contrast calculation\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Calculate standard deviation of pixel intensities\n",
    "        std_dev = np.std(gray_image)\n",
    "        \n",
    "        # Check if the image meets the high-contrast threshold\n",
    "        if std_dev >= contrast_threshold:\n",
    "            high_contrast_images.append(image_path)\n",
    "    print(len(high_contrast_images))\n",
    "    # Visualize the high-contrast images\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    for i, img_path in enumerate(high_contrast_images):\n",
    "        img = cv2.imread(img_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB for display\n",
    "\n",
    "        # Display each high-contrast image\n",
    "        plt.subplot(1, len(high_contrast_images), i + 1)\n",
    "        plt.imshow(img_rgb)\n",
    "        plt.title(f\"High Contrast Image {i+1}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return high_contrast_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7247b253-5a03-4bc3-a112-1b0d64f9f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "folder_path = \"wildfire-week8/test/testloader-original/\"\n",
    "high_contrast_images = filter_and_visualize_high_contrast_images(folder_path, contrast_threshold=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802f1aaa-e40e-41d6-aa72-8fed740667ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "increase_highlights_auto_threshold(\"wildfire-week8/test/testloader-original/original_image_9.png\",\"wildfire-week8/test/highlighted9.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af3ebac-3fe9-45c2-b4cd-cade6a37ba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "increase_highlights_auto_threshold(\"wildfire-week8/test/testloader-original/original_image_53.png\",\"wildfire-week8/test/highlighted53.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63a5ba7-0b9b-47e7-a740-9da338f0a133",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_image('wildfire-week8/test/highlighted9.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63649990-a426-422f-afc9-9d45c4c61baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_image('wildfire-week8/test/highlighted53.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec87b94-28ee-44db-8259-1bc899a95672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def color_based_segmentation(image):\n",
    "    \"\"\"Generates a mask for alive trees based on color segmentation.\"\"\"\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    lower_green = np.array([25, 40, 20])   # Lowered brightness and saturation to capture darker greens\n",
    "    upper_green = np.array([100, 255, 180])\n",
    "    green_mask = cv2.inRange(hsv_image, lower_green, upper_green)\n",
    "    return green_mask\n",
    "\n",
    "def filter_and_visualize_high_contrast_images(folder_path, contrast_threshold):\n",
    "    \"\"\"\n",
    "    Filters and visualizes images with high contrast from a specified folder.\n",
    "    Parameters:\n",
    "    - folder_path: Path to the folder containing images.\n",
    "    - contrast_threshold: Threshold for standard deviation to consider an image as high contrast.\n",
    "    Returns:\n",
    "    - List of file paths of high-contrast images.\n",
    "    \"\"\"\n",
    "    high_contrast_images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            continue\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        std_dev = np.std(gray_image)\n",
    "        if std_dev >= contrast_threshold:\n",
    "            high_contrast_images.append(image_path)\n",
    "    \n",
    "    # Visualize the high-contrast images\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    for i, img_path in enumerate(high_contrast_images):\n",
    "        img = cv2.imread(img_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        plt.subplot(1, len(high_contrast_images), i + 1)\n",
    "        plt.imshow(img_rgb)\n",
    "        plt.title(f\"High Contrast Image {i+1}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return high_contrast_images\n",
    "\n",
    "# def increase_highlights_auto_threshold(image_path, output_path, highlight_amount=2, percentile=50):\n",
    "#     \"\"\"\n",
    "#     Increases highlights in the image by brightening the brightest regions.\n",
    "#     Automatically determines a threshold based on the brightness distribution.\n",
    "#     Parameters:\n",
    "#     - image_path: Path to the image file.\n",
    "#     - highlight_amount: Multiplier for highlight brightness (e.g., 1.2 = 20% increase).\n",
    "#     - percentile: Percentile to use for determining the brightness threshold.\n",
    "#     \"\"\"\n",
    "#     image = cv2.imread(image_path)\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "#     h, s, v = cv2.split(hsv)\n",
    "#     threshold = np.percentile(v, percentile)\n",
    "#     highlight_mask = v > threshold\n",
    "#     v[highlight_mask] = np.clip(v[highlight_mask] * highlight_amount, 0, 255)\n",
    "#     hsv_highlighted = cv2.merge([h, s, v])\n",
    "#     highlighted_image = cv2.cvtColor(hsv_highlighted, cv2.COLOR_HSV2RGB)\n",
    "#     highlighted_image_bgr = cv2.cvtColor(highlighted_image, cv2.COLOR_RGB2BGR)\n",
    "#     cv2.imwrite(output_path, highlighted_image_bgr)\n",
    "#     return highlighted_image_bgr\n",
    "\n",
    "def process_images(original_folder, water_mask_folder, water_mask_applied_folder, output_format='png', contrast_threshold=30):\n",
    "    \"\"\"\n",
    "    Processes all images in the specified folders, applies tree detection methods, \n",
    "    and visualizes results after filtering high-contrast images and enhancing highlights.\n",
    "    \"\"\"\n",
    "    # Step 1: Filter for high-contrast images\n",
    "    high_contrast_images = filter_and_visualize_high_contrast_images(original_folder, contrast_threshold)\n",
    "\n",
    "    # Step 2: Loop through each high-contrast image\n",
    "    for image_path in high_contrast_images:\n",
    "        image_file = os.path.basename(image_path)\n",
    "        \n",
    "        # Enhance highlights in the high-contrast image\n",
    "        highlighted_image_path = os.path.join(original_folder, f\"highlighted_{image_file}\")\n",
    "        highlighted_image = increase_highlights_auto_threshold(image_path, highlighted_image_path)\n",
    "        print(highlighted_image_path)\n",
    "\n",
    "        # Read the corresponding water mask (e.g., predicted_mask_0.png)\n",
    "        water_mask_file = f'predicted_mask_{image_file.split(\".\")[0].split(\"_\")[-1]}.png'\n",
    "        water_mask_path = os.path.join(water_mask_folder, water_mask_file)\n",
    "        water_mask = cv2.imread(water_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if water_mask is None:\n",
    "            print(f\"Error: Could not read water mask from {water_mask_path}.\")\n",
    "            continue\n",
    "\n",
    "        # Read the water mask applied image (e.g., predicted_overlay_1.png)\n",
    "        water_mask_applied_file = f'predicted_overlay_{image_file.split(\".\")[0].split(\"_\")[-1]}.png'\n",
    "        water_mask_applied_path = os.path.join(water_mask_applied_folder, water_mask_applied_file)\n",
    "        water_mask_applied_image = cv2.imread(water_mask_applied_path)\n",
    "\n",
    "        if water_mask_applied_image is None:\n",
    "            print(f\"Error: Could not read water mask applied image from {water_mask_applied_path}.\")\n",
    "            continue\n",
    "\n",
    "        # Use color-based segmentation to detect alive trees\n",
    "        alive_tree_mask = color_based_segmentation(highlighted_image)\n",
    "\n",
    "        # Exclude areas identified as water in the water mask\n",
    "        alive_tree_mask[water_mask > 0] = 0  # Set alive tree mask to 0 where water mask is present\n",
    "\n",
    "        # Create transparent overlay for alive trees\n",
    "        alive_tree_overlay = np.zeros_like(highlighted_image, dtype=np.uint8)\n",
    "        alive_tree_overlay[alive_tree_mask > 0] = [0, 255, 0]  # Green for alive trees\n",
    "\n",
    "        # Combine overlays with the provided water mask applied image\n",
    "        alpha_trees = 1\n",
    "        final_overlay_image = cv2.addWeighted(water_mask_applied_image, 1, alive_tree_overlay, alpha_trees, 0)\n",
    "\n",
    "        # Save the final overlay image\n",
    "        output_filename = f'final_overlay_{os.path.splitext(image_file)[0]}.{output_format}'\n",
    "        output_path = os.path.join(water_mask_applied_folder, output_filename)\n",
    "        cv2.imwrite(output_path, final_overlay_image)\n",
    "\n",
    "        # Visualize the original image, water mask applied image, and final image with tree overlay\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Original Image')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(highlighted_image)\n",
    "        plt.title('Processed Image')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(cv2.cvtColor(final_overlay_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Final Image with Alive Tree Overlay')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "    print(f\"Final overlay images saved in '{water_mask_applied_folder}' with format '{output_format}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979cab8e-8adc-4691-a78a-5a499bd41951",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_folder = 'wildfire-week8/test/testloader-original'        # Change this to your image folder path\n",
    "water_mask_folder = 'wildfire-week8/test/testloader-predict'\n",
    "water_mask_applied_folder = 'wildfire-week8/test/water-overlay'\n",
    "\n",
    "process_images(original_folder, water_mask_folder, water_mask_applied_folder, output_format='png', contrast_threshold=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1c4674-1f5b-45fc-9a58-b0436c474fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def process_images_trees(original_folder, contrast_threshold=30, output_format='png'):\n",
    "    \"\"\"\n",
    "    Processes all images in the specified folder, applies tree detection methods,\n",
    "    and visualizes results after filtering high-contrast images and enhancing highlights.\n",
    "    \"\"\"\n",
    "    # Step 1: Filter for high-contrast images\n",
    "    high_contrast_images = filter_and_visualize_high_contrast_images(original_folder, contrast_threshold)\n",
    "\n",
    "    # Step 2: Loop through each high-contrast image\n",
    "    for image_path in high_contrast_images:\n",
    "        image_file = os.path.basename(image_path)\n",
    "        \n",
    "        # Enhance highlights in the high-contrast image\n",
    "        highlighted_image_path = os.path.join(original_folder, f\"highlighted_{image_file}\")\n",
    "        highlighted_image = increase_highlights_auto_threshold(image_path, highlighted_image_path)\n",
    "        print(f\"Highlighted image saved at: {highlighted_image_path}\")\n",
    "\n",
    "        # Use color-based segmentation to detect alive trees on the highlighted image\n",
    "        alive_tree_mask = color_based_segmentation(highlighted_image)\n",
    "\n",
    "        # Create transparent overlay for alive trees\n",
    "        alive_tree_overlay = np.zeros_like(highlighted_image, dtype=np.uint8)\n",
    "        alive_tree_overlay[alive_tree_mask > 0] = [0, 255, 0]  # Green for alive trees\n",
    "\n",
    "        # Combine overlays with the highlighted image\n",
    "        alpha_trees = 1.0\n",
    "        final_overlay_image = cv2.addWeighted(highlighted_image, 1, alive_tree_overlay, alpha_trees, 0)\n",
    "\n",
    "        # Save the final overlay image\n",
    "        output_filename = f'final_overlay_{os.path.splitext(image_file)[0]}.{output_format}'\n",
    "        output_path = os.path.join(original_folder, output_filename)\n",
    "        cv2.imwrite(output_path, final_overlay_image)\n",
    "\n",
    "        # Visualize the original image, highlighted image, and final overlay image\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Original Image')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(highlighted_image)\n",
    "        plt.title('Highlighted Image')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(final_overlay_image)\n",
    "        plt.title('Final Image with Alive Tree Overlay')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "    print(f\"Final overlay images saved in '{original_folder}' with format '{output_format}'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dc3f95-fe88-49b0-b20c-21652546f529",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_folder = 'wildfire-week8/valid/original' \n",
    "process_images_trees(original_folder, contrast_threshold=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed7ec34-5003-4cd9-a5e3-9d9b0fd57346",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_image('wildfire-week8/valid/original/DJI_0554_JPG.rf.6396d4a2947f673a85d2defb0b535bb6.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580e137e-42ac-4c79-a736-36c097b8f307",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
