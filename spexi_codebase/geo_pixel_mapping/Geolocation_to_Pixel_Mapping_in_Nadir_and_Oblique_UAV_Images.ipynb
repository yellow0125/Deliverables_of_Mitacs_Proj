{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYBULvself2h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c3c3be7-5263-4eff-e733-d26b57933ca6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting osmnx\n",
            "  Downloading osmnx-2.0.3-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: geopandas>=1.0 in /usr/local/lib/python3.11/dist-packages (from osmnx) (1.0.1)\n",
            "Requirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.11/dist-packages (from osmnx) (3.5)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from osmnx) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.11/dist-packages (from osmnx) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.27 in /usr/local/lib/python3.11/dist-packages (from osmnx) (2.32.3)\n",
            "Requirement already satisfied: shapely>=2.0 in /usr/local/lib/python3.11/dist-packages (from osmnx) (2.1.1)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from geopandas>=1.0->osmnx) (0.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from geopandas>=1.0->osmnx) (24.2)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from geopandas>=1.0->osmnx) (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4->osmnx) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4->osmnx) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4->osmnx) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27->osmnx) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27->osmnx) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27->osmnx) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27->osmnx) (2025.4.26)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4->osmnx) (1.17.0)\n",
            "Downloading osmnx-2.0.3-py3-none-any.whl (100 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.2/100.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: osmnx\n",
            "Successfully installed osmnx-2.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade osmnx"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and Setup"
      ],
      "metadata": {
        "id": "4vS1J3Ugofjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import math\n",
        "import os\n",
        "from geopy.distance import geodesic\n",
        "from PIL import Image, ImageDraw\n",
        "import pandas as pd\n",
        "from shapely.geometry import Point, Polygon\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "import requests\n",
        "import sys\n",
        "from IPython.display import Image as IPyImage, display\n",
        "from shapely.geometry import shape, Polygon, Point\n",
        "import osmnx as ox\n",
        "from PIL import Image, ImageDraw\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "lJoaQLTOoqTF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7c5c9e9-862d-417d-b9cf-e643f32b460d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Geocoding & Map Display"
      ],
      "metadata": {
        "id": "PTJ86buCuLeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lat_lon_from_address(address):\n",
        "    \"\"\"\n",
        "    Uses the Google Geocoding API to convert a physical address into\n",
        "    geographic coordinates (latitude and longitude).\n",
        "    Parameters:\n",
        "        address (str): The address to geocode.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (latitude, longitude) if successful.\n",
        "    Raises:\n",
        "        ValueError: If no results are found for the given address.\n",
        "        Exception: If the API request fails.\n",
        "    \"\"\"\n",
        "    base_url = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
        "    params = {\n",
        "        \"address\": address,\n",
        "        \"key\": GOOGLE_API_KEY\n",
        "    }\n",
        "    response = requests.get(base_url, params=params)\n",
        "    if response.status_code == 200:\n",
        "        results = response.json().get('results')\n",
        "        if results:\n",
        "            location = results[0]['geometry']['location']\n",
        "            return location['lat'], location['lng']\n",
        "        else:\n",
        "            raise ValueError(f\"No results found for address: {address}\")\n",
        "    else:\n",
        "        raise Exception(f\"Geocoding API error: {response.status_code}\")\n",
        "\n",
        "\n",
        "def geocode_and_display_map(lat, lon,address):\n",
        "    \"\"\"\n",
        "    Displays a satellite map of the given latitude and longitude using Google Static Maps API.\n",
        "\n",
        "    Parameters:\n",
        "        lat (float): Latitude of the location.\n",
        "        lon (float): Longitude of the location.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    try:\n",
        "        print(f\"Coordinates: {lat}, {lon}\")\n",
        "        lat, lon = get_lat_lon_from_address(address)\n",
        "        # Build the Google Static Map URL with a marker at the location\n",
        "        map_url = (\n",
        "            f\"https://maps.googleapis.com/maps/api/staticmap?\"\n",
        "            f\"center={lat},{lon}&zoom=16&size=600x400&scale=2&maptype=satellite\"\n",
        "            f\"&markers=size:tiny|color:red|label:A|{lat},{lon}\"\n",
        "            f\"&key={GOOGLE_API_KEY}\"\n",
        "        )\n",
        "\n",
        "\n",
        "        # print(\"Map URL:\", map_url)\n",
        "        display(IPyImage(url=map_url))\n",
        "\n",
        "    except Exception as e:\n",
        "        # print(f\"Error: {e}\")\n",
        "        print(f\"\\nNo image footprint contains the target location)\")\n",
        "        print(\"Please try another address or check your image metadata.\")\n",
        "        sys.exit()"
      ],
      "metadata": {
        "id": "4tkB3h2SuIyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Coordinate & Pixel Utilities"
      ],
      "metadata": {
        "id": "hGdWwt-zpQoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create folders for output\n",
        "os.makedirs(\"cropped_images\", exist_ok=True)\n",
        "os.makedirs(\"annotated_images\", exist_ok=True)\n",
        "os.makedirs(\"test\", exist_ok=True)\n",
        "\n",
        "\n",
        "def parse_image_coords(coords_str):\n",
        "    part = coords_str.split(\"POINT(\")[1].split(\")\")[0]\n",
        "    lon_str, lat_str = part.strip().split()\n",
        "    return float(lat_str), float(lon_str)\n",
        "\n",
        "def compute_bearing(lat1, lon1, lat2, lon2):\n",
        "    \"\"\"\n",
        "    Calculates the bearing (direction angle) from a start point (lat1, lon1)\n",
        "    to an end point (lat2, lon2).\n",
        "\n",
        "    Parameters:\n",
        "        lat1, lon1 (float): Latitude and longitude of the start point.\n",
        "        lat2, lon2 (float): Latitude and longitude of the target point.\n",
        "\n",
        "    Returns:\n",
        "        float: Bearing in degrees, ranging from 0° to 360°.\n",
        "    \"\"\"\n",
        "    lat1_rad = math.radians(lat1)\n",
        "    lat2_rad = math.radians(lat2)\n",
        "    dlon_rad = math.radians(lon2 - lon1)\n",
        "    x = math.sin(dlon_rad) * math.cos(lat2_rad)\n",
        "    y = math.cos(lat1_rad) * math.sin(lat2_rad) - math.sin(lat1_rad) * math.cos(lat2_rad) * math.cos(dlon_rad)\n",
        "    bearing = math.degrees(math.atan2(x, y))\n",
        "    return (bearing + 360) % 360\n",
        "\n",
        "\n",
        "def get_next_folder_number(base_path):\n",
        "    existing = [int(name) for name in os.listdir(base_path) if name.isdigit()]\n",
        "    return str(max(existing, default=0) + 1)"
      ],
      "metadata": {
        "id": "1DYOkDTtp6Ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lat/Lon to Pixel Conversion"
      ],
      "metadata": {
        "id": "O1NM6QpQpTZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def latlon_to_pixel(drone_lat, drone_lon, altitude, heading, gimbal_pitch,\n",
        "                    target_lat, target_lon, image_width, image_height, hfov, vfov, image_name=\"unknown\"):\n",
        "    \"\"\"\n",
        "    Converts the geographic coordinates of a target point into pixel coordinates\n",
        "    within an image captured by a UAV, accounting for camera orientation and FOV.\n",
        "\n",
        "    For nadir images, it uses a GSD-based projection.\n",
        "    For oblique images, it uses angular projection based on heading and pitch.\n",
        "\n",
        "    Parameters:\n",
        "        drone_lat, drone_lon (float): Coordinates of the UAV.\n",
        "        altitude (float): UAV altitude above ground in meters.\n",
        "        heading (float): UAV heading angle in degrees.\n",
        "        gimbal_pitch (float): Camera gimbal pitch angle in degrees.\n",
        "        target_lat, target_lon (float): Geographic coordinates of the target.\n",
        "        image_width, image_height (int): Dimensions of the image in pixels.\n",
        "        hfov, vfov (float): Horizontal and vertical field of view in degrees.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (x_pixel, y_pixel, delta_azimuth, delta_elevation,\n",
        "                horizontal_distance, total_pitch)\n",
        "    \"\"\"\n",
        "    if gimbal_pitch <= -87 and gimbal_pitch >= -92:  # Nadir case\n",
        "\n",
        "        # Compute the full ground coverage in meters based on altitude and camera FOV\n",
        "        ground_width = 2 * altitude * math.tan(math.radians(hfov / 2))\n",
        "        ground_height = 2 * altitude * math.tan(math.radians(vfov / 2))\n",
        "        meter_per_pixel_x = ground_width / image_width\n",
        "        meter_per_pixel_y = ground_height / image_height\n",
        "\n",
        "        dlat_deg = target_lat - drone_lat\n",
        "        dlon_deg = target_lon - drone_lon\n",
        "        dy_m = dlat_deg * 110540         # north/south difference in meters\n",
        "        dx_m = dlon_deg * (111320 * math.cos(math.radians(drone_lat)))  # east/west difference\n",
        "\n",
        "        dx_px = -dx_m / meter_per_pixel_x\n",
        "        dy_px =  dy_m / meter_per_pixel_y\n",
        "\n",
        "        x_pixel = image_width / 2 + dx_px\n",
        "        y_pixel = image_height / 2 + dy_px\n",
        "        horizontal_distance = geodesic((drone_lat, drone_lon), (target_lat, target_lon)).meters\n",
        "\n",
        "        return x_pixel, y_pixel, 0, 90, horizontal_distance, -90\n",
        "\n",
        "    else:\n",
        "        # Oblique images\n",
        "        horizontal_distance = geodesic((drone_lat, drone_lon), (target_lat, target_lon)).meters\n",
        "        measured_bearing = compute_bearing(drone_lat, drone_lon, target_lat, target_lon)\n",
        "        normalized_heading = heading % 360\n",
        "        delta_azimuth = measured_bearing - normalized_heading\n",
        "\n",
        "        if delta_azimuth > 180:\n",
        "            delta_azimuth -= 360\n",
        "        elif delta_azimuth < -180:\n",
        "            delta_azimuth += 360\n",
        "\n",
        "        total_pitch = -90.0 if horizontal_distance == 0 else -math.degrees(math.atan2(altitude, horizontal_distance))\n",
        "        delta_elevation = total_pitch - gimbal_pitch\n",
        "\n",
        "        x_pixel = image_width / 2 + (delta_azimuth * image_width / hfov)\n",
        "        y_pixel = image_height / 2 - (delta_elevation * image_height / vfov)\n",
        "        return x_pixel, y_pixel, delta_azimuth, delta_elevation, horizontal_distance, total_pitch"
      ],
      "metadata": {
        "id": "zQZ8JMo1qVSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Selection"
      ],
      "metadata": {
        "id": "u1bAFHdrpgbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_polygon_coords(polygon_str):\n",
        "    \"\"\"\n",
        "    Extracts coordinate pairs from a WKT polygon string (SRID=4326;POLYGON).\n",
        "    This is typically used to retrieve the footprint of an image.\n",
        "\n",
        "    Parameters:\n",
        "        polygon_str (str): Polygon in WKT format as a string.\n",
        "            Example: 'SRID=4326;POLYGON((lon1 lat1, lon2 lat2, ..., lonN latN))'\n",
        "\n",
        "    Returns:\n",
        "        list of tuples: A list of (longitude, latitude) coordinates defining the polygon.\n",
        "    \"\"\"\n",
        "    coords = polygon_str.replace(\"SRID=4326;POLYGON((\", \"\").replace(\"))\", \"\").split(\",\")\n",
        "    return [(float(coord.split()[0]), float(coord.split()[1])) for coord in coords]\n",
        "\n",
        "\n",
        "def load_and_filter_metadata(target_lat, target_lon,metadata_path):\n",
        "    \"\"\"\n",
        "    Loads image metadata from a CSV file and filters it to retain only those images\n",
        "    whose polygon footprints contain the specified target location.\n",
        "\n",
        "    Parameters:\n",
        "        target_lat (float): Latitude of the target location.\n",
        "        target_lon (float): Longitude of the target location.\n",
        "        metadata_path (str): Full path to the metadata CSV file.\n",
        "\n",
        "    Returns:\n",
        "        DataFrame: A filtered DataFrame containing only images that contain the target point.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(metadata_path)\n",
        "    df[['longitude', 'latitude']] = df['image_coords'].str.extract(\n",
        "        r'SRID=4326;POINT\\(([-\\d.]+) ([-]?\\d+\\.\\d+)\\)'\n",
        "    ).astype(float)\n",
        "    df[\"polygon_coords\"] = df['footprint'].apply(extract_polygon_coords)\n",
        "    target_point = Point(target_lon, target_lat)\n",
        "    df[\"contains_target\"] = df[\"polygon_coords\"].apply(lambda coords: Polygon(coords).contains(target_point))\n",
        "    df_filtered = df[df[\"contains_target\"]].copy()\n",
        "\n",
        "    if df_filtered.empty:\n",
        "        print(f\"\\nNo image footprint contains the target location: ({target_lat}, {target_lon})\")\n",
        "        print(\"Please try another address or check your image metadata.\")\n",
        "\n",
        "        sys.exit()\n",
        "\n",
        "\n",
        "    if not df_filtered.empty:\n",
        "        df_filtered[\"distance\"] = df_filtered.apply(\n",
        "            lambda row: geodesic(\n",
        "                (row[\"latitude\"], row[\"longitude\"]), (target_lat, target_lon)\n",
        "            ).meters,\n",
        "            axis=1\n",
        "        )\n",
        "    return df_filtered\n",
        "\n",
        "\n",
        "\n",
        "def select_nadir_oblique_images(df_filtered):\n",
        "    \"\"\"\n",
        "    From the filtered metadata, selects the most suitable nadir image (camera facing down)\n",
        "    and one oblique image per cardinal direction (North, East, South, West) if available.\n",
        "\n",
        "    Parameters:\n",
        "        df_filtered (DataFrame): The filtered metadata containing relevant UAV images.\n",
        "\n",
        "    Returns:\n",
        "        DataFrame: A combined DataFrame of the selected nadir and oblique images with direction labels.\n",
        "    \"\"\"\n",
        "    nadir_range_filtered = df_filtered[\n",
        "    (df_filtered[\"gimbal_pitch\"] >= -92) &\n",
        "    (df_filtered[\"gimbal_pitch\"] <= -87)\n",
        "]\n",
        "    nadir_idx = (nadir_range_filtered[\"gimbal_pitch\"] + 90).abs().idxmin() \\\n",
        "        if not nadir_range_filtered.empty else None\n",
        "    nadir_image = df_filtered.loc[[nadir_idx]] if not pd.isna(nadir_idx) else pd.DataFrame()\n",
        "    df_filtered[\"normalized_heading\"] = df_filtered[\"heading\"].apply(lambda x: (x + 180) % 360 - 180)\n",
        "    directions = {\"North\": 0, \"East\": 90, \"South\": 180, \"West\": -90}\n",
        "    df_oblique_candidates = df_filtered[\n",
        "    ((df_filtered[\"gimbal_pitch\"] >= 15) & (df_filtered[\"gimbal_pitch\"] <= 45)) |\n",
        "    ((df_filtered[\"gimbal_pitch\"] >= -45) & (df_filtered[\"gimbal_pitch\"] <= -15))\n",
        "    ].copy()\n",
        "\n",
        "    oblique_images = pd.DataFrame()\n",
        "    for direction, angle in directions.items():\n",
        "        heading_min = angle - 15\n",
        "        heading_max = angle + 15\n",
        "        condition_heading = df_oblique_candidates[\"normalized_heading\"].between(heading_min, heading_max)\n",
        "        oblique = df_oblique_candidates[condition_heading].sort_values(\"distance\").head(1)\n",
        "        if not oblique.empty:\n",
        "            oblique[\"direction\"] = direction\n",
        "            oblique_images = pd.concat([oblique_images, oblique])\n",
        "\n",
        "    if not nadir_image.empty:\n",
        "        nadir_image[\"direction\"] = \"Nadir (Center)\"\n",
        "    return pd.concat([nadir_image, oblique_images]).reset_index(drop=True)\n",
        "def display_metadata(filtered_df, selected):\n",
        "    print(\"\\nAll available images with their metadata:\")\n",
        "    for _, row in filtered_df.iterrows():\n",
        "        img_filename = os.path.basename(row['image_uri'])\n",
        "        print(f\"Image URI: {img_filename}, Latitude: {row['latitude']}, Longitude: {row['longitude']}, Heading: {row['heading']}°, Gimbal Pitch: {row['gimbal_pitch']}°\")\n",
        "\n",
        "    print(\"\\nSelected images for cropping:\")\n",
        "    for _, row in selected.iterrows():\n",
        "        print(f\"{row['direction']}: {row['image_uri']} (Heading: {row['heading']}°, Pitch: {row['gimbal_pitch']}°)\")"
      ],
      "metadata": {
        "id": "aaymHfb4qplB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OSM Polygon Extraction"
      ],
      "metadata": {
        "id": "D99V5AtSptyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_building_polygon(lat, lon):\n",
        "    \"\"\"\n",
        "    Extract the building polygon (if any) from OSM that contains the given lat/lon.\n",
        "    Returns a Shapely polygon or None if not found.\n",
        "    \"\"\"\n",
        "    target_point = Point(lon, lat)\n",
        "    tags = {\"building\": True}\n",
        "    buildings = ox.features_from_point((lat, lon), tags=tags, dist=50)\n",
        "    polygons = buildings[buildings.geom_type.isin(['Polygon', 'MultiPolygon'])]\n",
        "    matched = polygons[polygons.geometry.contains(target_point)]\n",
        "    return matched.geometry.iloc[0] if not matched.empty else None\n",
        "\n",
        "\n",
        "def polygon_to_pixels(polygon, nadir_row, width, height, hfov, vfov, shift_x=0, shift_y=0):\n",
        "    \"\"\"\n",
        "    Convert lat/lon coordinates of a polygon to pixel coordinates using nadir image parameters.\n",
        "    Apply an  pixel shift for better alignment.\n",
        "    \"\"\"\n",
        "    coords = list(polygon.exterior.coords)\n",
        "    pixel_coords = []\n",
        "    for lon, lat in coords:\n",
        "        px, py, *_ = latlon_to_pixel(\n",
        "            nadir_row['latitude'], nadir_row['longitude'], nadir_row['altitude'],\n",
        "            nadir_row['heading'], nadir_row['gimbal_pitch'],\n",
        "            lat, lon,\n",
        "            width, height,\n",
        "            hfov, vfov\n",
        "        )\n",
        "\n",
        "        pixel_coords.append((px + shift_x, py + shift_y))\n",
        "    return pixel_coords\n",
        "\n",
        "\n",
        "def crop_nadir_building_polygon(nadir_row, target_lat, target_lon, image_dir, hfov, vfov):\n",
        "    image_name = os.path.basename(nadir_row['image_uri'])\n",
        "    image_path = os.path.join(image_dir, image_name)\n",
        "    if not os.path.exists(image_path):\n",
        "        print(f\"Image not found: {image_path}\")\n",
        "        return None\n",
        "\n",
        "    image = Image.open(image_path)\n",
        "    width, height = image.size\n",
        "\n",
        "    # Get building polygon from OSM\n",
        "    building_polygon = extract_building_polygon(target_lat, target_lon)\n",
        "    if building_polygon is None:\n",
        "        print(\"❌ No building polygon found at this location.\")\n",
        "        return None\n",
        "\n",
        "    pixel_coords = polygon_to_pixels(building_polygon, nadir_row, width, height, hfov, vfov, shift_x=0, shift_y=0)\n",
        "    xs, ys = zip(*pixel_coords)\n",
        "    min_x, max_x = min(xs), max(xs)\n",
        "    min_y, max_y = min(ys), max(ys)\n",
        "\n",
        "    # Calculate width and height of the box\n",
        "    box_width = max_x - min_x\n",
        "    box_height = max_y - min_y\n",
        "\n",
        "    # Expand by 20%\n",
        "    expand_x = box_width * 0.2\n",
        "    expand_y = box_height * 0.2\n",
        "\n",
        "    crop_box = (\n",
        "        int(max(min_x - expand_x / 2, 0)),\n",
        "        int(max(min_y - expand_y / 2, 0)),\n",
        "        int(min(max_x + expand_x / 2, width)),\n",
        "        int(min(max_y + expand_y / 2, height))\n",
        "    )\n",
        "\n",
        "    cropped = image.crop(crop_box)\n",
        "\n",
        "    # Save the cropped image\n",
        "    output_path = os.path.join(\"cropped_images\", \"nadir_building_crop.jpg\")\n",
        "    cropped.save(output_path)\n",
        "    print(f\"✅ Nadir building crop saved to: {output_path}\")\n",
        "\n",
        "    # Overlay polygon on the original image\n",
        "    overlay = image.copy()\n",
        "    draw = ImageDraw.Draw(overlay)\n",
        "    draw.polygon(pixel_coords, outline=\"red\", width=10)\n",
        "    overlay_path = os.path.join(\"annotated_images\", \"nadir_building_overlay.jpg\")\n",
        "    overlay.save(overlay_path)\n",
        "    print(f\"✅ Nadir image with polygon overlay saved to: {overlay_path}\")\n",
        "    return (\"Nadir\", cropped)\n",
        "\n",
        "def overlay_nadir_building_on_obliques(selected_df, building_polygon, image_dir, hfov=69.6, vfov=55.2):\n",
        "    \"\"\"\n",
        "    Projects OSM building polygon onto oblique images with oblique-specific correction.\n",
        "    \"\"\"\n",
        "    cropped_oblique_buildings = []\n",
        "    numbered_folder = get_next_folder_number(\"cropped_images\")\n",
        "    cropped_folder = os.path.join(\"cropped_images\", numbered_folder)\n",
        "    annotated_folder = os.path.join(\"annotated_images\", numbered_folder)\n",
        "    os.makedirs(cropped_folder, exist_ok=True)\n",
        "    os.makedirs(annotated_folder, exist_ok=True)\n",
        "    for _, row in selected_df.iterrows():\n",
        "        if row['direction'] == \"Nadir (Center)\":\n",
        "            continue\n",
        "\n",
        "        image_name = os.path.basename(row['image_uri'])\n",
        "        image_path = os.path.join(image_dir, image_name)\n",
        "        if not os.path.exists(image_path):\n",
        "            print(f\"Image not found: {image_path}\")\n",
        "            continue\n",
        "\n",
        "        image = Image.open(image_path)\n",
        "        width, height = image.size\n",
        "\n",
        "        pixel_coords = []\n",
        "        for lon, lat in building_polygon.exterior.coords:\n",
        "            px, py, *_ = latlon_to_pixel(\n",
        "                row['latitude'], row['longitude'], row['altitude'],\n",
        "                row['heading'], row['gimbal_pitch'],\n",
        "                lat, lon,\n",
        "                width, height, hfov, vfov\n",
        "            )\n",
        "\n",
        "            # Apply **oblique-specific offset**\n",
        "            # print(px, py)\n",
        "            px, py = apply_polynomial_offset_model(px, py)\n",
        "            # print(px, py)\n",
        "\n",
        "            pixel_coords.append((px, py))\n",
        "        xs, ys = zip(*pixel_coords)\n",
        "        min_x, max_x = min(xs), max(xs)\n",
        "        min_y, max_y = min(ys), max(ys)\n",
        "        box_width = max_x - min_x\n",
        "        box_height = max_y - min_y\n",
        "\n",
        "\n",
        "        # Expand%\n",
        "        expand_x = box_width * 0.8\n",
        "        expand_y = box_height * 0.8\n",
        "        vertical_shift = int(0.4 * box_height)\n",
        "\n",
        "        crop_box = (\n",
        "      int(max(min_x - expand_x / 2, 0)),\n",
        "      int(max(min_y - expand_y / 2 + vertical_shift, 0)),\n",
        "      int(min(max_x + expand_x / 2, width)),\n",
        "      int(min(max_y + expand_y / 2 + vertical_shift, height))\n",
        "  )\n",
        "\n",
        "        cropped = image.crop(crop_box)\n",
        "        print(crop_box)\n",
        "\n",
        "\n",
        "        # Annotate polygon on oblique image\n",
        "        annotated = image.copy()\n",
        "        draw = ImageDraw.Draw(annotated)\n",
        "        draw.polygon(pixel_coords, outline=\"blue\", width=10)\n",
        "\n",
        "        overlay_path = os.path.join(annotated_folder, f\"oblique_overlay_{row['direction']}_{image_name}\")\n",
        "        annotated.save(overlay_path)\n",
        "        print(f\"✅ Saved oblique overlay: {overlay_path}\")\n",
        "        cropped_path = os.path.join(cropped_folder, f\"oblique_crop_{row['direction']}_{image_name}\")\n",
        "        cropped.save(cropped_path)\n",
        "        cropped_oblique_buildings.append((row['direction'], cropped))\n",
        "    return cropped_oblique_buildings\n"
      ],
      "metadata": {
        "id": "WdgyPHuFq_FB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Offset Correction Models"
      ],
      "metadata": {
        "id": "aJfryyjZpy9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "model_dx = joblib.load(\"model_dx.pkl\")\n",
        "model_dy = joblib.load(\"model_dy.pkl\")\n",
        "\n",
        "\n",
        "def apply_polynomial_offset_model(x, y):\n",
        "    input_point = np.array([[x, y]])\n",
        "    dx = model_dx.predict(input_point)[0]\n",
        "    dy = model_dy.predict(input_point)[0]\n",
        "    return x + dx, y + dy\n",
        "\n"
      ],
      "metadata": {
        "id": "PNOwuOcZrA7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Execution"
      ],
      "metadata": {
        "id": "R5XQ_H5vrHN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  image_dir = '/content/images'\n",
        "  metadata_file = '/content/NE-metadata-sample.csv'\n",
        "  GOOGLE_API_KEY = ''\n",
        "\n",
        "  os.makedirs('cropped_images', exist_ok=True)\n",
        "  os.makedirs('annotated_images', exist_ok=True)\n",
        "\n",
        "  if not os.path.exists(image_dir):\n",
        "      raise FileNotFoundError(f\"Image directory not found at {image_dir}\")\n",
        "\n",
        "  if not os.path.exists(metadata_file):\n",
        "      raise FileNotFoundError(f\"Metadata file not found at {metadata_file}\")\n",
        "\n",
        "  if not GOOGLE_API_KEY:\n",
        "      raise ValueError(\"Google API key is missing. Please provide a valid key.\")\n",
        "\n",
        "\n",
        "  # For testing with existing images, you can use this address:\n",
        "  # PWPC+V3F Lakewood, Colorado, USA\n",
        "  address =input(\"Enter an address: \")\n",
        "  lat, lon = get_lat_lon_from_address(address)\n",
        "  geocode_and_display_map(lat, lon,address)\n",
        "\n",
        "  filtered_df = load_and_filter_metadata(lat, lon,metadata_file)\n",
        "  selected = select_nadir_oblique_images(filtered_df)\n",
        "  display_metadata(filtered_df, selected)\n",
        "\n",
        "  building_polygon = extract_building_polygon(lat, lon)\n",
        "\n",
        "  if not building_polygon:\n",
        "    print(\"No building found for the given coordinates.\")\n",
        "\n",
        "\n",
        "\n",
        "  if building_polygon is not None:\n",
        "    nadir_selected = selected[selected[\"direction\"] == \"Nadir (Center)\"]\n",
        "    if not nadir_selected.empty:\n",
        "        nadir_row = nadir_selected.iloc[0]\n",
        "        nadir_cropped = crop_nadir_building_polygon(nadir_row, lat, lon, image_dir, hfov=69.6, vfov=55.2)\n",
        "        oblique_cropped = overlay_nadir_building_on_obliques(selected, building_polygon, image_dir, hfov=69.6, vfov=55.2)\n",
        "        all_cropped = [nadir_cropped] + oblique_cropped\n",
        "    else:\n",
        "        print(\"⚠️ No nadir image found. Proceeding with oblique images only.\")\n",
        "        all_cropped = overlay_nadir_building_on_obliques(selected, building_polygon, image_dir, hfov=69.6, vfov=55.2)\n",
        "\n",
        "    if all_cropped:\n",
        "        fig, axs = plt.subplots(1, len(all_cropped), figsize=(5 * len(all_cropped), 5))\n",
        "        if len(all_cropped) == 1:\n",
        "            axs = [axs]\n",
        "        for ax, (label, img) in zip(axs, all_cropped):\n",
        "            ax.imshow(img)\n",
        "            ax.set_title(label)\n",
        "            ax.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"combined_cropped_images.jpg\")\n",
        "        plt.show()\n",
        "        plt.close(fig)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "imwb6C2ZrNMs",
        "outputId": "e87509f8-68e9-4a6c-97c9-6923f001f8fa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3022419186.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mGOOGLE_API_KEY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cropped_images'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'annotated_images'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "3OMMUTnEnIOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -s ifconfig.me"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdsbFeZD4n00",
        "outputId": "59e057f7-566e-4291-a683-ed50d10e2df5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.73.25.36"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "#  Load your data from Excel\n",
        "df = pd.read_excel(\"offset_data_v2.xlsx\")  # Replace with your filename\n",
        "\n",
        "# 📐 Define input features and target offsets\n",
        "X = df[['x_pixel_pred', 'y_pixel_pred']].values\n",
        "y_dx = df['x_pixel_actual'] - df['x_pixel_pred']\n",
        "y_dy = df['y_pixel_actual'] - df['y_pixel_pred']\n",
        "\n",
        "# 🧪 Split into training and test sets\n",
        "X_train, X_test, y_dx_train, y_dx_test, y_dy_train, y_dy_test = train_test_split(\n",
        "    X, y_dx, y_dy, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "#  Create polynomial regression models\n",
        "model_dx = make_pipeline(PolynomialFeatures(2), LinearRegression())\n",
        "model_dy = make_pipeline(PolynomialFeatures(2), LinearRegression())\n",
        "\n",
        "#  Train the models\n",
        "model_dx.fit(X_train, y_dx_train)\n",
        "model_dy.fit(X_train, y_dy_train)\n",
        "\n",
        "#  Evaluate the models\n",
        "dx_pred = model_dx.predict(X_test)\n",
        "dy_pred = model_dy.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "rmse_dx = sqrt(mean_squared_error(y_dx_test, dx_pred))\n",
        "rmse_dy = sqrt(mean_squared_error(y_dy_test, dy_pred))\n",
        "\n",
        "\n",
        "print(f\"📏 Test RMSE (dx): {rmse_dx:.2f} pixels\")\n",
        "print(f\"📏 Test RMSE (dy): {rmse_dy:.2f} pixels\")\n",
        "\n",
        "\n",
        "# 🔁 Load trained models\n",
        "joblib.dump(model_dx, \"model_dx.pkl\")\n",
        "joblib.dump(model_dy, \"model_dy.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6VgRtPkuqg6",
        "outputId": "51339d5e-e12c-44d0-8af9-1625f3cc72e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📏 Test RMSE (dx): 118.40 pixels\n",
            "📏 Test RMSE (dy): 56.75 pixels\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model_dy.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}